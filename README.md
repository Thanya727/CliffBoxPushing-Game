# CliffBoxPushing-Game
This project centers around the implementation and evaluation of a Reinforcement Learning (RL) algorithm, such as Q-learning or SARSA, to solve the challenging CliffBoxPushing grid-world game. The grid-world environment, depicted in Figure 1, poses a complex scenario where an agent must navigate to push a box to a goal position while avoiding dangerous cliffs. The project encourages novel implementations and ideas, offering bonus credit for creative solutions. The implementation involves coding the RL algorithm and presenting a convincing demonstration through a presentation. Relevant resources from OpenAI Spinning Up are recommended for gaining insights into current RL algorithms.
The 2D grid world is a 6x14 space, where the agent (A), box (B), goal (G), and cliffs (x) are positioned. The RL agent needs to learn to push the box to the goal, considering the game's termination conditions: stepping into the cliff, reaching the maximum time step, or successfully moving the box to the goal. The Markov Decision Process (MDP) formulation includes states, actions, rewards, and transitions. States represent the positions of the agent and box, actions correspond to up, down, left, or right movements, and rewards encompass various factors such as timestep penalties, distance penalties, and cliff-related rewards. Transitions are managed by the step() function in the environment
![The Cliff Box Pushing Grid World.](https://drive.google.com/drive/u/0/my-drive)
